[
  {
    "path": "posts/2021-06-12-building-distill/",
    "title": "Building a {distill} website",
    "description": "How I built this site using {distill}",
    "author": [
      {
        "name": "dondon",
        "url": {}
      }
    ],
    "date": "2021-06-12",
    "categories": [],
    "contents": "\r\nHere is where I will talk about building this website.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-06-12-building-distill/image1.png",
    "last_modified": "2021-06-12T18:49:56+09:00",
    "input_file": {},
    "preview_width": 1863,
    "preview_height": 834
  },
  {
    "path": "posts/2021-06-12-nonparametric-regression/",
    "title": "Nonparametric Regression",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "dondon",
        "url": {}
      }
    ],
    "date": "2021-06-12",
    "categories": [
      "Statistics",
      "R"
    ],
    "contents": "\r\n\r\nContents\r\nNon-parametric regression\r\nRegressogram\r\nExample\r\nKernel estimator\r\n\r\n\r\nNon-parametric regression\r\n비모수 회귀분석은 함수의 형태를 가정하지 않는 회귀모형을 의미한다. 모수적 회귀모형에서는 보통 \\(Y = \\beta_0 + \\beta_1X_1 + ... + \\beta_pX_p + \\epsilon\\) 형태의 선형성을 가정했다(모수적 회귀모형에는 선형성을 가정하지 않는 비선형 회귀모형도 포함된다).\r\n반면에 비모수 회귀모형에서는 고정된 함수의 형태를 가정하지 않고 단순히 smooth function을 가정한다.\r\n표본 (X_1,Y_1), …(X_n,Y_n)이 주어졌을 때 우리가 추정하고자 하는 회귀 함수는 다음과 같이 정의된다.\r\n\\[\r\nY = m(X) + \\epsilon, \\quad m(x) = E(Y|X = x), \\quad E(\\epsilon) = 0\r\n\\]\r\nRegressogram\r\n가장 단순한 비모수추정치는 regressogram이다.\r\n논의의 편의를 위해 설명변수를 1개만 가정한다. 또한 X는 0과 1사이의 값을 갖는다고 가정한다.\r\n먼저 \\([0, 1]\\) 구간을 k개의 bin으로 쪼갠다. 쪼갠 각 구간에 포함되는 관측치의 갯수를 계산한다.\r\n\\[B_1 = [0, h], \\quad B_2= [h, 2h], ...  \\] \\(n_j\\) : \\(B_j\\)에 포함되는 관측치의 갯수 \\(n_j = \\sum_{i}I(X_i \\in B_j), \\quad I(X_i \\in B_j) = \\begin{cases} 1, & \\mbox{if }\\mbox{X가 B_j에 포함될 경우} \\\\ 0, & \\mbox{if }n\\mbox{ X가 B_j에 포함되지 않을 경우} \\end{cases}\\)\r\n\\(B_j\\) 구간에서의 \\(Y_i\\)들의 평균 \\(\\bar{Y}_j\\)는 다음과 같이 정의된다.\\[\\bar{Y}_j = \\frac{1}{n_j} \\sum_{X_i \\in B_j} Y_i\\]\r\n마지막으로 \\(\\hat{m}(x)\\)는 모든 \\(B_j\\)구간에서의 \\(\\bar{Y}_j\\)의 합으로 정의된다. \\[\\hat{m}(x) = \\sum_{j = 1}^k \\bar{Y_j}I(x \\in B_j)\\]\r\nExample\r\n\\(Y_i = sin(X_i) + \\epsilon\\)라는 모형에서 생성한 50개의 자료이다. 이 경우 \\(m(x) = sin(x)\\)이고 \\(X_i \\sim U(-2, 2)\\), \\(\\epsilon_i \\sim N(0, \\frac{1}{9})\\)이다.\r\n\r\n\r\nn = 50\r\nset.seed(1233)\r\nx = runif(n, -2, 2)\r\ny = sin(x)+rnorm(n, mean = 0, sd = 1/3)\r\n\r\n\r\n\r\n구간의 갯수 k를 어떻게 지정하는지에 따라 \\(\\hat{m}(x)\\)는 undersmooth될 수도 있고 oversmooth될 수도 있다. 따라서 적절한 k를 지정하는 것이 중요하다(뒤에 cross-validation 참고).\r\n\r\n\r\nrunning_mean = function(x,y,left,right,k){\r\n        n = length(x)\r\n        B = seq(left,right,length=k+1)\r\n        # 어떤 값이 구간에 있을 때 어느 구간에 속할지 알려주는 함수NAWhichBin = findInterval(x,B)  \r\n        # 각 구간에 포함되어 있는 관측치의 개수NAN = tabulate(WhichBin)  \r\n        m.hat = rep(0,k)\r\n        for(j in 1:k){\r\n                if(N[j]>0) m.hat[j] = mean(y[WhichBin == j])\r\n        }\r\n        return(list(bins=B,m.hat=m.hat))\r\n}\r\n\r\n\r\n\r\n\r\n\r\nfit_10 <- running_mean(x, y, left = -2, right = 2, k = 10)\r\nfit_30 <- running_mean(x, y, left = -2, right = 2, k = 30)\r\ndata.frame(x,y) %>% ggplot(aes( x = x, y = y)) +\r\n        geom_point() + \r\n        geom_line(data = data.frame(x = x, y = sin(x)), aes(x = x, y = y)) +  \r\n        geom_line(data = data.frame(x = fit_10$bins, y = c(fit_10$m.hat, fit_10$m.hat[10])),\r\n                  aes(x =x, y = y),\r\n                  color = 'red')+\r\n         geom_line(data = data.frame(x = fit_30$bins, y = c(fit_30$m.hat, fit_30$m.hat[30])), \r\n                  aes(x = x, y = y), \r\n                  color = 'blue') + \r\n        ylim(c(-2, 2))\r\n\r\n\r\n\r\n\r\n\r\n\r\nHoRM::regressogram(x = x, y = y, nbins = 10, show.bins = T, show.lines = T, show.means = F, main = 'regressogram')\r\n\r\n\r\n\r\n\r\n\\(k = 10\\)일 때 red line을 보면 적절하게 추정된 것으로 보인다. \\(k = 30\\)일 때 blue line을 보면 oversmooth된 것처럼 보인다.\r\nKernel estimator\r\n커널 추정법은 회귀함수 \\(f\\)의 추정치 \\(\\hat{f}\\)가 \\(\\mathbf{y} = (Y_1, Y_2, ..., Y_n)^t\\)의 선형결합으로 표현된다는 전제 하에서 출발한다. 즉, \\(\\hat{f}(x) = \\sum w_iY_i\\)으로 추정하고자 하는데 가중치 \\(w_i\\)를 어떻게 정해주는지가 핵심이다.\r\n이어서 정리 예정\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-06-12-nonparametric-regression/nonparametric-regression_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2021-06-12T20:44:27+09:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-06-12-em-algorithm/",
    "title": "EM algorithm",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "dondon",
        "url": {}
      }
    ],
    "date": "2021-06-12",
    "categories": [
      "Statistics",
      "R"
    ],
    "contents": "\r\n\r\nContents\r\nEM algorithm for Two component Gaussian Mixture model\r\nTwo component Gaussian Mixture another example\r\nMultinomial example\r\n\r\n\r\nEM algorithm for Two component Gaussian Mixture model\r\n\r\n\r\ndat <- c(-0.39, 0.12, 0.94, 1.67, 1.76, 2.44, 3.72, 4.28, 4.92, 5.53,\r\n         0.06, 0.48, 1.01, 1.68, 1.80, 3.25, 4.12, 4.60, 5.28, 6.22)\r\n\r\nhist(dat, probability = T, breaks = seq(-0.5, 6.5, length.out = 15), main = '')\r\n\r\n\r\n\r\n\r\nn = 20 데이터는 bimodal 형태를 띄고 있다. 이 데이터는 어떤 분포로부터 나왔는가?\r\n우리가 아는 대부분의 분포는 unimodal(단봉) 형태로 bimodal(쌍봉) 형태에 대해서는 잘모른다. 따라서 추론을 해야하는데 가장 쉽게 생각할 수 있는 것은 두개의 정규분포를 혼합한 형태로 생각하는 것이다. 이러한 분포를 mixture distribution이라고 한다. bimodal(쌍봉) 형태의 분포는 두 개의 정규분포를 결합한 mixture distribution이라는 가설을 세웠으므로 문제를 풀기 위해서는 분포의 형태를 결정하는 모수를 알아야 한다. 즉, 정규 분포에 대한 모수 \\(\\mu_1, \\mu_2, \\sigma_1^2, \\sigma_2^2\\)를 알아야 한다. 추가적으로 두 분포 중에 데이터가 어느 분포에서 나왔는지를 수량화하는 모수 \\(P(Z = 1) = \\pi\\)를 추가한다. 따라서 가설을 풀기 위해서는 \\(\\mu_1, \\mu_2, \\sigma_1^2, \\sigma_2^2, \\pi\\) 총 5개의 모수를 추정해야 한다. 만약에 \\(P(Z = 1) = \\pi\\)를 알고 있으면 나머지 4개의 모수는 두 분포가 독립이므로 MLE를 통해서 구할 수 있다. 하지만 \\(Z\\)는 가상적으로 만든 random variable이므로 \\(\\pi\\)를 알 수 없다. 따라서 \\(\\pi\\)를 구하기 위해서 iteration을 수렴할 때까지 해서 \\(\\pi\\)를 추정한다.\r\n\\(data = (0.39, 0.12, 0.94, 1.67, 1.76, 2.44, 3.72, 4.28, 4.92, 5.53,0.06, 0.48, 1.01, 1.68, 1.80, 3.25, 4.12, 4.60, 5.28, 6.22)\\)\r\n\\(Y_1 \\sim N(\\mu_1, \\sigma_1^2)\\)\r\n\\(Y_2 \\sim N(\\mu_2, \\sigma_2^2)\\)\r\n\\(Y = (1-Z)Y_1 + ZY_2\\)\r\n\\(P(Z = 1) = \\pi\\), \\(Z = 0\\) if \\(\\mu_2, \\sigma_2^2\\)을 모수로 갖는 정규분포일 경우\r\n\\(\\hat{\\mu_1},\\hat{\\mu_2},\\hat{\\sigma_1}^2, \\hat{\\sigma_2}^2, \\hat{\\pi}\\) 에 대한 초기값을 설정한다.\r\n\r\n\r\ny <- c(-0.39, 0.06, 0.12, 0.48, 0.94, 1.01, 1.67, 1.68, 1.76, 1.80, 2.44, 3.25, 3.72, 4.12, 4.28, 4.60, 4.92, 5.28, 5.53, 6.22 )\r\nn <- length(y)\r\ny1 <- c(-0.39, 0.06, 0.12, 0.48, 0.94, 1.01, 1.67, 1.68, 1.76, 1.80, 2.44)\r\ny2 <- c(3.25, 3.72, 4.12, 4.28, 4.60, 4.92, 5.28, 5.53, 6.22)\r\nmu1 <- mean(y1)\r\nmu2 <-  mean(y2)\r\ns1 <- var(y1)\r\ns2 <- var(y2)\r\nphat <- 0.5\r\n\r\n\r\n\r\nE-step\r\n\\[\\hat {\\gamma}_i = \\frac{\\hat{\\pi}\\phi_{\\hat{\\theta}_2}(y_i)}{(1-\\hat{\\pi}) \\phi_{\\hat{\\theta}_1}(y_i)+\\hat{\\pi}\\phi_{\\hat{\\theta}_2}(y_i)}\\] \\(i = 1,2,....,n\\)\r\n\r\n\r\nres <- vector() \r\nfor (i in 1:n) {\r\n        a <- phat*dnorm(y[i], mean = mu2, sd = s2)\r\n        b <- (1-phat)*dnorm(y[i], mean = mu1, sd = s1)+phat*dnorm(y[i], mean = mu2, sd = s2)\r\n        res[i] <- a/(a+b)\r\n}\r\nres\r\n\r\n\r\n [1] 2.196263e-07 1.663506e-06 2.186560e-06 1.146965e-05 9.945000e-05\r\n [6] 1.387198e-04 3.356555e-03 3.524375e-03 5.207622e-03 6.329995e-03\r\n[11] 1.203763e-01 4.772492e-01 4.980510e-01 4.997759e-01 4.999067e-01\r\n[16] 4.999841e-01 4.999974e-01 4.999997e-01 4.999999e-01 5.000000e-01\r\n\r\nM-step\r\n\\(\\hat{\\mu_1}=\\frac{\\sum_{i=1}^n (1-\\hat{\\gamma_i})y_i}{\\sum_{i=1}^n(1-\\hat{\\gamma_i})}\\),\\(\\hat{\\mu_2}=\\frac{\\sum_{i=1}^n \\hat{\\gamma_i}y_i}{\\sum_{i=1}^n \\hat{\\gamma_i}}\\), \\(\\hat{\\sigma_1}=\\frac{\\sum_{i=1}^n (1-\\hat{\\gamma_i})(y_i-\\hat{\\mu_1}^2)}{\\sum_{i=1}^n(1-\\hat{\\gamma_i})}\\),\\(\\hat{\\sigma_2}=\\frac{\\sum_{i=1}^n \\hat{\\gamma_i}(y_i-\\hat{\\mu_2}^2)}{\\sum_{i=1}^n\\hat{\\gamma_i}}\\),\r\n\r\n\r\nmu1 <- sum((1-res)*y)/sum(1-res)\r\nmu2 <- sum(res*y)/sum(res)\r\ns1 <- sqrt(sum((1-res)*(y-mu1)^2)/sum(1-res))\r\n        s2 <- sqrt(sum(res*(y-mu2)^2)/sum(res))\r\n        phat <- mean(res)\r\n\r\n\r\n\r\nE-M step 반복\r\n\r\n\r\ny <- c(-0.39, 0.06, 0.12, 0.48, 0.94, 1.01, 1.67, 1.68, 1.76, 1.80, 2.44, 3.25, 3.72, 4.12, 4.28, 4.60, 4.92, 5.28, 5.53, 6.22 )\r\nn <- length(y)\r\nN <- 100\r\ny1 <- c(-0.39, 0.06, 0.12, 0.48, 0.94, 1.01, 1.67, 1.68, 1.76, 1.80, 2.44)\r\ny2 <- c(3.25, 3.72, 4.12, 4.28, 4.60, 4.92, 5.28, 5.53, 6.22)\r\nmu1 <- mean(y1)\r\nmu2 <-  mean(y2)\r\ns1 <- var(y1)\r\ns2 <- var(y2)\r\nphat <- 0.5\r\n\r\nresult <- vector()\r\n\r\nfor (j in 1:N) {\r\n        \r\n        # E-step \r\n        res <- phat*dnorm(y, mean = mu2, sd = s2)/((1-phat)*dnorm(y, mean = mu1, sd = s1)+phat*dnorm(y, mean = mu2, sd = s2))\r\n        \r\n        # M-step \r\n        mu1 <- sum((1-res)*y)/sum(1-res)\r\n        mu2 <- sum(res*y)/sum(res)\r\n        s1 <- sqrt(sum((1-res)*(y-mu1)^2)/sum(1-res))\r\n        s2 <- sqrt(sum(res*(y-mu2)^2)/sum(res))\r\n        phat <- mean(res)\r\n        \r\n        # result\r\n        result[j] <- sum(log((1-phat)*dnorm(y, mu1, s1) + phat*dnorm(y, mu2, s2)))\r\n        \r\n        if(j>1){\r\n                if(result[j]-result[j-1]<1e-8){\r\n                        result <- result[1:j]\r\n                        break\r\n                        }\r\n                \r\n        }\r\n        j <- j+1\r\n\r\n}\r\nmu1\r\n\r\n\r\n[1] 1.083143\r\n\r\nmu2\r\n\r\n\r\n[1] 4.655892\r\n\r\ns1\r\n\r\n\r\n[1] 0.9007445\r\n\r\ns2\r\n\r\n\r\n[1] 0.9048893\r\n\r\nTwo component Gaussian Mixture another example\r\n일반적으로 흐린 날에는 맑은 날보다 온도가 낮다. 10일 동안의 온도 데이터가 주어졌을 때 맑은 날과 흐린 날의 평균 온도는 얼마인가? (10일 동안의 온도는 주어졌지만 흐린 날의 온도인지 맑은 날의 온도인지 모른다)\r\nk = 2, 각 k별로 정규분포 가정(\\(\\sigma_0 = 10\\)), 즉 bimodal distribution 형태가 됨.\r\n주어진 데이터와 parameter는 다음과 같다.\r\n\\(temerature = (70, 62, 89, 54, 97, 75, 82, 56, 32, 78)\\)\r\n\\(k = 2\\)\r\n\\(\\mu_1 = 80\\) initial value\r\n\\(\\mu_2 = 55\\) initial value\r\n\\(Z_{ij} = 1\\), x가 첫번째 정규분포에서 발생했을 경우\r\n\\(Z_{ij} = 0\\), x가 두번째 정규분포에서 발생했을 경우\r\n\\(X_i\\) : observed\r\n\\(Z_{ij}\\) : unobservable\r\n초기값을 설정한다.\r\n\r\n\r\ntemp <- c(70, 62, 89, 54, 97, 75, 82, 56, 32, 78)\r\nn <- length(temp)\r\nmu1 <- 80 # initial value\r\nmu2 <- 55 # initial value \r\n\r\n\r\n\r\nE- Step\r\n\\[E[Z_{ij}] = \\frac{P(X=x_i|\\mu = \\mu_j)}{\\sum_{k=1}^2 P(X=x_i|\\mu = \\mu_k)} = \\frac{\\exp(-\\frac{1}{2\\sigma^2}(x_i-\\mu_j)^2)}{\\sum_{k=1}^2\\exp(-\\frac{1}{2\\sigma^2}(x_i-\\mu_k)^2)}\\]\r\n\\[E[Z_{11}] = \\frac{exp(-\\frac{1}{2\\times 100} (70-80)^2)}{exp(-\\frac{1}{2\\times 100} (70-80)^2)+exp(-\\frac{1}{2\\times 100} (70-55)^2)} = 0.65\\]\r\n\\[E[Z_{12}] = \\frac{exp(-\\frac{1}{2\\times 100} (70-55)^2)}{exp(-\\frac{1}{2\\times 100} (70-80)^2)+exp(-\\frac{1}{2\\times 100} (70-55)^2)} = 0.34\\]\r\n\\(E[Z_{i1}] = (0.65, 0.20, 0.99, 0.03, 0.99, 0.86, 0.97, 0.053, 0.00, 0.93)\\) \\(E[Z_{i2}] = (0.34, 0.79, 0.00, 0.96, 0.00, 0.13, 0.02, 0.94, 0.99, 0.067)\\)\r\n\r\n\r\nEZ1 <- vector()\r\nEZ2 <- vector()\r\n\r\nfor (i in 1:n) {\r\n        L1 <- dnorm(x = temp[i], mean = mu1, sd = 10)\r\n        L2 <- dnorm(x = temp[i], mean = mu2, sd = 10)\r\n        EZ1[i] <- L1/(L1+L2)\r\n        EZ2[i] <- L2/(L1+L2)\r\n}\r\nEZ1\r\n\r\n\r\n [1] 0.6513548647 0.2018132223 0.9953904278 0.0330859784 0.9993736658\r\n [6] 0.8670357598 0.9740426428 0.0534033298 0.0001398221 0.9324533089\r\n\r\nEZ2\r\n\r\n\r\n [1] 0.3486451353 0.7981867777 0.0046095722 0.9669140216 0.0006263342\r\n [6] 0.1329642402 0.0259573572 0.9465966702 0.9998601779 0.0675466911\r\n\r\nM - Step\r\n\\[\\mu_j \\longleftarrow \\frac{\\sum_{i=1}^m E[Z_{ij}]X_i}{\\sum_{i=1}^m E[Z_{ij}]}\\]\r\n\\[\\mu_1 \\longleftarrow  \\frac{0.65\\times 70+0.20\\times62+0.99\\times89+....+0.93\\times78}{0.65+0.20+0.99+....+0.93}=81.75\\] \\[\\mu_2 \\longleftarrow  \\frac{0.34\\times 70+0.79\\times62+....+0.067\\times78}{0.34+0.79+0.00+....+0.067}=53.35\\]\r\n\r\n\r\nnumerator1 <- vector()\r\nnumerator2 <- vector()\r\n\r\nfor (i in 1:n) {\r\n        numerator1[i] <- temp[i]*EZ1[i]\r\n        numerator2[i] <- temp[i]*EZ2[i]\r\n}\r\n\r\nsum(numerator1)/sum(EZ1) # update value \r\n\r\n\r\n[1] 81.64697\r\n\r\nsum(numerator2)/sum(EZ2) # update value \r\n\r\n\r\n[1] 53.34494\r\n\r\n수렴할 때까지 E - step, M - step 반복\r\n\r\n\r\ntemp <- c(70, 62, 89, 54, 97, 75, 82, 56, 32, 78)\r\nmu <- c(80, 55) # initial value\r\nmu.old <- mu+1\r\ntol <- .Machine$double.eps^0.5\r\nn <- length(temp)\r\nj <- 0\r\n\r\nEZ1 <- vector()\r\nEZ2 <- vector()\r\nnumerator1 <- vector()  \r\nnumerator2 <- vector()\r\n\r\n\r\nwhile(TRUE){\r\n  for (i in 1:n) {\r\n    L1 <- dnorm(x = temp[i], mean = mu[1], sd = 10)\r\n    L2 <- dnorm(x = temp[i], mean = mu[2], sd = 10)\r\n    EZ1[i] <- L1/(L1+L2)\r\n    EZ2[i] <- L2/(L1+L2)\r\n        \r\n    numerator1[i] <- temp[i]*EZ1[i]\r\n    numerator2[i] <- temp[i]*EZ2[i]\r\n    }\r\n  a <- sum(numerator1)/sum(EZ1) # update value \r\n  b <- sum(numerator2)/sum(EZ2) # update value \r\n  mu <- c(a, b)\r\n  j <- j+1\r\n  if(sum(abs(mu-mu.old)/mu.old)<tol | j > 1000){\r\n          break\r\n  }\r\n}\r\nmu\r\n\r\n\r\n[1] 81.73553 52.83098\r\n\r\nMultinomial example\r\n\r\n\r\ny1 <- 38\r\ny2 <- 34\r\ny3 <- 125\r\n\r\n\r\nx <- seq(0,1,0.01)\r\n\r\n# MLE \r\n\r\ny <- (-y1-y2-y3)*x^2 + (-2*y1-y2+y3)*x+2*y2\r\nplot(x, y, type = 'l')\r\nabline(h=0, \r\n       v = uniroot(function(x) (-y1-y2-y3)*x^2 + (-2*y1-y2+y3)*x+\r\n                           2*y2, c(0,1))[[1]])\r\n\r\n\r\n\r\n# log likelihood \r\nl <- y1*log(1/2-x/2)+y2*log(x/4)+y3*log(1/2+x/4)\r\nplot(x, l, type = 'l')\r\nabline(v = uniroot(function(x) (-y1-y2-y3)*x^2 + (-2*y1-y2+y3)*x+\r\n                           2*y2, c(0,1))[[1]])\r\n\r\n\r\n\r\n# use EM algorithm \r\nt1 <- 0.2\r\nfor (i in 1:10) {\r\n        y3.tmp <- 125*(t1/4)/(1/2+t1/4)\r\n        t2 <- (34+y3.tmp)/(72+y3.tmp)\r\n        t1 <- t2\r\n}\r\nt2\r\n\r\n\r\n[1] 0.6268215\r\n\r\n참고 1 : https://www.youtube.com/watch?v=RqA_kaaX6y4\r\n참고 2 : statistical computing with R second edition\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-06-12-em-algorithm/em-algorithm_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-06-12T20:52:15+09:00",
    "input_file": "em-algorithm.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  }
]
